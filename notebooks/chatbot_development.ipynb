{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# Employment Rights and Legal Advice Chatbot Development\\n',\n",
       "    '\\n',\n",
       "    'This notebook demonstrates the development and testing of our Employment Rights and Legal Advice Chatbot using the Gen AI Llama-3.1-70b-versatile model on GroqCloud.']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Install required libraries\\n',\n",
       "    '!pip install groq streamlit transformers torch SpeechRecognition pyttsx3']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['import os\\n',\n",
       "    'import json\\n',\n",
       "    'from groq import Groq\\n',\n",
       "    'from transformers import AutoTokenizer, AutoModel\\n',\n",
       "    'import speech_recognition as sr\\n',\n",
       "    'import pyttsx3']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Load configuration\\n',\n",
       "    \"with open('config.json', 'r') as config_file:\\n\",\n",
       "    '    config = json.load(config_file)\\n',\n",
       "    '\\n',\n",
       "    '# Set up Groq API key\\n',\n",
       "    'os.environ[\"GROQ_API_KEY\"] = \"your_api_key_here\"']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['class Chatbot:\\n',\n",
       "    '    def __init__(self):\\n',\n",
       "    '        self.client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\\n',\n",
       "    '\\n',\n",
       "    '    def generate_response(self, legal_analysis):\\n',\n",
       "    '        prompt = f\"\"\"\\n',\n",
       "    '        You are an AI assistant specializing in employment rights and labor laws. \\n',\n",
       "    \"        Based on the following legal analysis, provide a clear and concise response to the user's query:\\n\",\n",
       "    '\\n',\n",
       "    '        {legal_analysis}\\n',\n",
       "    '\\n',\n",
       "    '        Remember to:\\n',\n",
       "    '        1. Be informative but not overly technical\\n',\n",
       "    '        2. Provide actionable advice when appropriate\\n',\n",
       "    '        3. Encourage the user to seek professional legal counsel for complex issues\\n',\n",
       "    '\\n',\n",
       "    '        Response:\\n',\n",
       "    '        \"\"\"\\n',\n",
       "    '\\n',\n",
       "    '        chat_completion = self.client.chat.completions.create(\\n',\n",
       "    '            messages=[\\n',\n",
       "    '                {\\n',\n",
       "    '                    \"role\": \"user\",\\n',\n",
       "    '                    \"content\": prompt,\\n',\n",
       "    '                }\\n',\n",
       "    '            ],\\n',\n",
       "    \"            model=config['model'],\\n\",\n",
       "    \"            max_tokens=config['max_response_length'],\\n\",\n",
       "    \"            temperature=config['temperature']\\n\",\n",
       "    '        )\\n',\n",
       "    '\\n',\n",
       "    '        return chat_completion.choices[0].message.content\\n',\n",
       "    '\\n',\n",
       "    'chatbot = Chatbot()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['class LegalAnalyzer:\\n',\n",
       "    '    def __init__(self):\\n',\n",
       "    \"        with open('data/labor_laws.json', 'r') as f:\\n\",\n",
       "    '            self.labor_laws = json.load(f)\\n',\n",
       "    \"        with open('data/case_studies.json', 'r') as f:\\n\",\n",
       "    '            self.case_studies = json.load(f)\\n',\n",
       "    '\\n',\n",
       "    '    def analyze(self, query):\\n',\n",
       "    '        relevant_laws = self._find_relevant_laws(query)\\n',\n",
       "    '        relevant_cases = self._find_relevant_cases(query)\\n',\n",
       "    '        \\n',\n",
       "    '        analysis = f\"Relevant Laws:\\\\n{relevant_laws}\\\\n\\\\nRelevant Case Studies:\\\\n{relevant_cases}\"\\n',\n",
       "    '        return analysis\\n',\n",
       "    '\\n',\n",
       "    '    def _find_relevant_laws(self, query):\\n',\n",
       "    '        # Implement logic to find relevant laws based on the query\\n',\n",
       "    '        # This is a placeholder implementation\\n',\n",
       "    '        return \"Placeholder: Relevant labor laws would be listed here.\"\\n',\n",
       "    '\\n',\n",
       "    '    def _find_relevant_cases(self, query):\\n',\n",
       "    '        # Implement logic to find relevant case studies based on the query\\n',\n",
       "    '        # This is a placeholder implementation\\n',\n",
       "    '        return \"Placeholder: Relevant case studies would be listed here.\"\\n',\n",
       "    '\\n',\n",
       "    'legal_analyzer = LegalAnalyzer()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['class LanguageProcessor:\\n',\n",
       "    '    def __init__(self):\\n',\n",
       "    '        self.tokenizer = None\\n',\n",
       "    '        self.model = None\\n',\n",
       "    '        self.language = \"en\"\\n',\n",
       "    '\\n',\n",
       "    '    def set_language(self, language):\\n',\n",
       "    '        language_code = {\"English\": \"en\", \"Español\": \"es\", \"Français\": \"fr\"}\\n',\n",
       "    '        self.language = language_code[language]\\n',\n",
       "    '        self._load_model()\\n',\n",
       "    '\\n',\n",
       "    '    def _load_model(self):\\n',\n",
       "    '        model_path = f\"data/language_models/{self.language}_model.bin\"\\n',\n",
       "    '        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\\n',\n",
       "    '        self.model = AutoModel.from_pretrained(model_path)\\n',\n",
       "    '\\n',\n",
       "    '    def process(self, text):\\n',\n",
       "    '        # Tokenize and process the input text\\n',\n",
       "    '        tokens = self.tokenizer(text, return_tensors=\"pt\")\\n',\n",
       "    '        outputs = self.model(**tokens)\\n',\n",
       "    '        # Further processing logic here\\n',\n",
       "    '        return outputs\\n',\n",
       "    '\\n',\n",
       "    'language_processor = LanguageProcessor()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['class VoiceInterface:\\n',\n",
       "    '    def __init__(self):\\n',\n",
       "    '        self.recognizer = sr.Recognizer()\\n',\n",
       "    '        self.engine = pyttsx3.init()\\n',\n",
       "    '\\n',\n",
       "    '    def listen(self):\\n',\n",
       "    '        with sr.Microphone() as source:\\n',\n",
       "    '            print(\"Listening...\")\\n',\n",
       "    '            audio = self.recognizer.listen(source)\\n',\n",
       "    '            try:\\n',\n",
       "    '                text = self.recognizer.recognize_google(audio)\\n',\n",
       "    '                return text\\n',\n",
       "    '            except sr.UnknownValueError:\\n',\n",
       "    '                return \"Sorry, I couldn\\'t understand that.\"\\n',\n",
       "    '            except sr.RequestError:\\n',\n",
       "    '                return \"Sorry, there was an error processing your request.\"\\n',\n",
       "    '\\n',\n",
       "    '    def speak(self, text):\\n',\n",
       "    '        self.engine.say(text)\\n',\n",
       "    '        self.engine.runAndWait()\\n',\n",
       "    '\\n',\n",
       "    'voice_interface = VoiceInterface()']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['def process_query(query, language=\"English\"):\\n',\n",
       "    '    language_processor.set_language(language)\\n',\n",
       "    '    processed_input = language_processor.process(query)\\n',\n",
       "    '    legal_analysis = legal_analyzer.analyze(processed_input)\\n',\n",
       "    '    response = chatbot.generate_response(legal_analysis)\\n',\n",
       "    '    return response\\n',\n",
       "    '\\n',\n",
       "    '# Test the chatbot\\n',\n",
       "    'test_query = \"What are my rights regarding overtime pay?\"\\n',\n",
       "    'response = process_query(test_query)\\n',\n",
       "    'print(f\"Query: {test_query}\")\\n',\n",
       "    'print(f\"Response: {response}\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'source': ['# Test voice interface\\n',\n",
       "    'print(\"Please speak your question about employment rights:\")\\n',\n",
       "    'voice_query = voice_interface.listen()\\n',\n",
       "    'print(f\"You said: {voice_query}\")\\n',\n",
       "    '\\n',\n",
       "    'if voice_query != \"Sorry, I couldn\\'t understand that.\" and voice_query != \"Sorry, there was an error processing your request.\":\\n',\n",
       "    '    response = process_query(voice_query)\\n',\n",
       "    '    print(f\"Chatbot response: {response}\")\\n',\n",
       "    '    voice_interface.speak(response)']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.8.10'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Employment Rights and Legal Advice Chatbot Development\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the development and testing of our Employment Rights and Legal Advice Chatbot using the Gen AI Llama-3.1-70b-versatile model on GroqCloud.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Install required libraries\\n\",\n",
    "    \"!pip install groq streamlit transformers torch SpeechRecognition pyttsx3\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"from groq import Groq\\n\",\n",
    "    \"from transformers import AutoTokenizer, AutoModel\\n\",\n",
    "    \"import speech_recognition as sr\\n\",\n",
    "    \"import pyttsx3\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"with open('config.json', 'r') as config_file:\\n\",\n",
    "    \"    config = json.load(config_file)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up Groq API key\\n\",\n",
    "    \"os.environ[\\\"GROQ_API_KEY\\\"] = \\\"your_api_key_here\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"class Chatbot:\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.client = Groq(api_key=os.environ[\\\"GROQ_API_KEY\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def generate_response(self, legal_analysis):\\n\",\n",
    "    \"        prompt = f\\\"\\\"\\\"\\n\",\n",
    "    \"        You are an AI assistant specializing in employment rights and labor laws. \\n\",\n",
    "    \"        Based on the following legal analysis, provide a clear and concise response to the user's query:\\n\",\n",
    "    \"\\n\",\n",
    "    \"        {legal_analysis}\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Remember to:\\n\",\n",
    "    \"        1. Be informative but not overly technical\\n\",\n",
    "    \"        2. Provide actionable advice when appropriate\\n\",\n",
    "    \"        3. Encourage the user to seek professional legal counsel for complex issues\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Response:\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"        chat_completion = self.client.chat.completions.create(\\n\",\n",
    "    \"            messages=[\\n\",\n",
    "    \"                {\\n\",\n",
    "    \"                    \\\"role\\\": \\\"user\\\",\\n\",\n",
    "    \"                    \\\"content\\\": prompt,\\n\",\n",
    "    \"                }\\n\",\n",
    "    \"            ],\\n\",\n",
    "    \"            model=config['model'],\\n\",\n",
    "    \"            max_tokens=config['max_response_length'],\\n\",\n",
    "    \"            temperature=config['temperature']\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return chat_completion.choices[0].message.content\\n\",\n",
    "    \"\\n\",\n",
    "    \"chatbot = Chatbot()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"class LegalAnalyzer:\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        with open('data/labor_laws.json', 'r') as f:\\n\",\n",
    "    \"            self.labor_laws = json.load(f)\\n\",\n",
    "    \"        with open('data/case_studies.json', 'r') as f:\\n\",\n",
    "    \"            self.case_studies = json.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def analyze(self, query):\\n\",\n",
    "    \"        relevant_laws = self._find_relevant_laws(query)\\n\",\n",
    "    \"        relevant_cases = self._find_relevant_cases(query)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        analysis = f\\\"Relevant Laws:\\\\n{relevant_laws}\\\\n\\\\nRelevant Case Studies:\\\\n{relevant_cases}\\\"\\n\",\n",
    "    \"        return analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _find_relevant_laws(self, query):\\n\",\n",
    "    \"        # Implement logic to find relevant laws based on the query\\n\",\n",
    "    \"        # This is a placeholder implementation\\n\",\n",
    "    \"        return \\\"Placeholder: Relevant labor laws would be listed here.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _find_relevant_cases(self, query):\\n\",\n",
    "    \"        # Implement logic to find relevant case studies based on the query\\n\",\n",
    "    \"        # This is a placeholder implementation\\n\",\n",
    "    \"        return \\\"Placeholder: Relevant case studies would be listed here.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"legal_analyzer = LegalAnalyzer()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"class LanguageProcessor:\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.tokenizer = None\\n\",\n",
    "    \"        self.model = None\\n\",\n",
    "    \"        self.language = \\\"en\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def set_language(self, language):\\n\",\n",
    "    \"        language_code = {\\\"English\\\": \\\"en\\\", \\\"Español\\\": \\\"es\\\", \\\"Français\\\": \\\"fr\\\"}\\n\",\n",
    "    \"        self.language = language_code[language]\\n\",\n",
    "    \"        self._load_model()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _load_model(self):\\n\",\n",
    "    \"        model_path = f\\\"data/language_models/{self.language}_model.bin\\\"\\n\",\n",
    "    \"        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\\n\",\n",
    "    \"        self.model = AutoModel.from_pretrained(model_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def process(self, text):\\n\",\n",
    "    \"        # Tokenize and process the input text\\n\",\n",
    "    \"        tokens = self.tokenizer(text, return_tensors=\\\"pt\\\")\\n\",\n",
    "    \"        outputs = self.model(**tokens)\\n\",\n",
    "    \"        # Further processing logic here\\n\",\n",
    "    \"        return outputs\\n\",\n",
    "    \"\\n\",\n",
    "    \"language_processor = LanguageProcessor()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"class VoiceInterface:\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        self.recognizer = sr.Recognizer()\\n\",\n",
    "    \"        self.engine = pyttsx3.init()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def listen(self):\\n\",\n",
    "    \"        with sr.Microphone() as source:\\n\",\n",
    "    \"            print(\\\"Listening...\\\")\\n\",\n",
    "    \"            audio = self.recognizer.listen(source)\\n\",\n",
    "    \"            try:\\n\",\n",
    "    \"                text = self.recognizer.recognize_google(audio)\\n\",\n",
    "    \"                return text\\n\",\n",
    "    \"            except sr.UnknownValueError:\\n\",\n",
    "    \"                return \\\"Sorry, I couldn't understand that.\\\"\\n\",\n",
    "    \"            except sr.RequestError:\\n\",\n",
    "    \"                return \\\"Sorry, there was an error processing your request.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def speak(self, text):\\n\",\n",
    "    \"        self.engine.say(text)\\n\",\n",
    "    \"        self.engine.runAndWait()\\n\",\n",
    "    \"\\n\",\n",
    "    \"voice_interface = VoiceInterface()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def process_query(query, language=\\\"English\\\"):\\n\",\n",
    "    \"    language_processor.set_language(language)\\n\",\n",
    "    \"    processed_input = language_processor.process(query)\\n\",\n",
    "    \"    legal_analysis = legal_analyzer.analyze(processed_input)\\n\",\n",
    "    \"    response = chatbot.generate_response(legal_analysis)\\n\",\n",
    "    \"    return response\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test the chatbot\\n\",\n",
    "    \"test_query = \\\"What are my rights regarding overtime pay?\\\"\\n\",\n",
    "    \"response = process_query(test_query)\\n\",\n",
    "    \"print(f\\\"Query: {test_query}\\\")\\n\",\n",
    "    \"print(f\\\"Response: {response}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Test voice interface\\n\",\n",
    "    \"print(\\\"Please speak your question about employment rights:\\\")\\n\",\n",
    "    \"voice_query = voice_interface.listen()\\n\",\n",
    "    \"print(f\\\"You said: {voice_query}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if voice_query != \\\"Sorry, I couldn't understand that.\\\" and voice_query != \\\"Sorry, there was an error processing your request.\\\":\\n\",\n",
    "    \"    response = process_query(voice_query)\\n\",\n",
    "    \"    print(f\\\"Chatbot response: {response}\\\")\\n\",\n",
    "    \"    voice_interface.speak(response)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
